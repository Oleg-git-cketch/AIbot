import os
import logging
import requests
import json

from flask import Flask, request
import telebot
from buttons import menu_kb, role_kb, model_kb

TELEGRAM_TOKEN = os.getenv("BOT_TOKEN")
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY")

bot = telebot.TeleBot(TELEGRAM_TOKEN)
app = Flask(__name__)

user_roles = {}
user_model = {}

# –õ–æ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
logging.basicConfig(
    level=logging.INFO,
    filename='bot_errors.log',
    filemode='a',
    format='%(asctime)s - %(levelname)s - %(message)s'
)

# === Telegram Handlers ===

@bot.message_handler(commands=['start'])
def start(message):
    bot.send_message(message.chat.id, "üëã –î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å!\n\n–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤—ã–±–µ—Ä–∏—Ç–µ –ø—É–Ω–∫—Ç –º–µ–Ω—é –∏–ª–∏ –Ω–∞–ø–∏—à–∏—Ç–µ –ª—é–±–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ —á–∞—Ç —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å –æ–±—â–∞—Ç—å—Å—è —Å –ò–ò:", reply_markup=menu_kb())

@bot.message_handler(commands=['role'])
def role_command(message):
    bot.send_message(message.chat.id, 'üß† –í—ã–±–µ—Ä–∏—Ç–µ —Ä–æ–ª—å, –≤ –∫–æ—Ç–æ—Ä–æ–π –±–æ—Ç –±—É–¥–µ—Ç –æ—Ç–≤–µ—á–∞—Ç—å:', reply_markup=role_kb())

@bot.message_handler(commands=['model'])
def model_command(message):
    bot.send_message(message.chat.id, 'ü§ñ –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –ò–ò, —Å –∫–æ—Ç–æ—Ä–æ–π —Ö–æ—Ç–∏—Ç–µ –æ–±—â–∞—Ç—å—Å—è:', reply_markup=model_kb())

@bot.callback_query_handler(func=lambda call: call.data == "roles")
def role(call):
    bot.send_message(call.message.chat.id, 'üß† –í—ã–±–µ—Ä–∏—Ç–µ —Ä–æ–ª—å, –≤ –∫–æ—Ç–æ—Ä–æ–π –±–æ—Ç –±—É–¥–µ—Ç –æ—Ç–≤–µ—á–∞—Ç—å:', reply_markup=role_kb())

@bot.callback_query_handler(func=lambda call: call.data == "model")
def model(call):
    bot.send_message(call.message.chat.id, 'ü§ñ –í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –ò–ò, —Å –∫–æ—Ç–æ—Ä–æ–π —Ö–æ—Ç–∏—Ç–µ –æ–±—â–∞—Ç—å—Å—è:', reply_markup=model_kb())

@bot.callback_query_handler(func=lambda call: call.data.startswith('model_'))
def set_model(call):
    model_map = {
        "model_gpt4o": "openai/gpt-4o",
        "model_deepseek": "deepseek/deepseek-r1-0528-qwen3-8b:free",
        "model_gemini": "google/gemini-2.5-flash-preview-05-20"
    }
    model_id = model_map.get(call.data, "openai/gpt-4o")
    user_model[call.from_user.id] = model_id
    bot.send_message(call.message.chat.id, f'‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –≤—ã–±—Ä–∞–Ω–∞: {model_id}\n–¢–µ–ø–µ—Ä—å –Ω–∞–ø–∏—à–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ')

@bot.callback_query_handler(func=lambda call: call.data.startswith('role_'))
def set_role(call):
    role = call.data.replace('role_', '')
    user_roles[call.from_user.id] = role
    bot.send_message(call.message.chat.id, f"üé≠ –†–æ–ª—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞: {role}\n–¢–µ–ø–µ—Ä—å –Ω–∞–ø–∏—à–∏—Ç–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.")

@bot.callback_query_handler(func=lambda call: call.data == "start")
def start_ai(call):
    prompt = "–ü—Ä–∏–≤–µ—Ç! –ß—Ç–æ —Ç—ã —É–º–µ–µ—à—å?"
    role = user_roles.get(call.from_user.id, "assistant")
    model = user_model.get(call.from_user.id, "openai/gpt-4o")
    ask_ai(call.message.chat.id, prompt, call.message, role, model)

@bot.message_handler(func=lambda message: True)
def handle_message(message):
    prompt = message.text
    role = user_roles.get(message.from_user.id, 'assistant')
    model = user_model.get(message.from_user.id, 'openai/gpt-4o')
    ask_ai(message.chat.id, prompt, message, role, model)

# === –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –∫ OpenRouter ===

def ask_ai(chat_id, prompt, message, role, model):
    system_roles = {
        'assistant': f"–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –∫—Ä–∞—Ç–∫–æ –∏ –≤–µ–∂–ª–∏–≤–æ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã. –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {message.from_user.username}",
        'teacher': f"–¢—ã —Å—Ç—Ä–æ–≥–∏–π –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å, –æ–±—ä—è—Å–Ω—è—é—â–∏–π —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏. –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {message.from_user.username}",
        'shutnik': f"–¢—ã –≤–µ—Å—ë–ª—ã–π –±–æ—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–≤–µ—á–∞–µ—Ç —Å —é–º–æ—Ä–æ–º. –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {message.from_user.username}"
    }
    system_msg = system_roles.get(role, "–¢—ã –ø—Ä–æ—Å—Ç–æ –ø–æ–º–æ—â–Ω–∏–∫.")

    data = {
        "model": model,
        "max_tokens": 1000,
        "messages": [
            {"role": "system", "content": system_msg},
            {"role": "user", "content": prompt}
        ]
    }

    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json"
    }

    try:
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            data=json.dumps(data),
            timeout=20
        )
        response.raise_for_status()
        reply = response.json()['choices'][0]['message']['content']
    except Exception as e:
        logging.exception(f"[AI ERROR] –û—à–∏–±–∫–∞: {e}")
        reply = "‚ö†Ô∏è –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞ –∫ –ò–ò."

    try:
        bot.send_message(chat_id, reply)
    except Exception as e:
        logging.exception(f"[SEND ERROR] –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")

# === Flask —Å–µ—Ä–≤–µ—Ä –¥–ª—è Webhook ===

@app.route(f'/{TELEGRAM_TOKEN}', methods=['POST'])
def webhook():
    update = telebot.types.Update.de_json(request.stream.read().decode("utf-8"))
    bot.process_new_updates([update])
    return "ok", 200

@app.route('/', methods=['GET'])
def home():
    return '–ë–æ—Ç —Ä–∞–±–æ—Ç–∞–µ—Ç!'

# === –£—Å—Ç–∞–Ω–æ–≤–∫–∞ Webhook –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ ===

if __name__ == "__main__":
    webhook_url = f"https://{os.getenv('RAILWAY_STATIC_URL')}/{TELEGRAM_TOKEN}"
    bot.remove_webhook()
    bot.set_webhook(url=webhook_url)
    app.run(host="0.0.0.0", port=int(os.environ.get("PORT", 5000)))
